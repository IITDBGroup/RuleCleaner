{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b115201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from rbbm_src.dc_src.DCRepair import (eq_op, \n",
    " non_symetric_op,\n",
    "#  dc_tuple_violation_template_targeted_t1,\n",
    "#  dc_tuple_violation_template_targeted_t2\n",
    ")\n",
    "import re\n",
    "from rbbm_src.dc_src.src.classes import parse_rule_to_where_clause\n",
    "from string import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fbbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn=psycopg2.connect('dbname=cr user=postgres')\n",
    "dc_tuple_violation_template_targeted_t1=\\\n",
    "Template(\"SELECT DISTINCT $t1_desc,$t2_desc FROM $table t1, $table t2 WHERE $dc_desc\")\n",
    "dc_tuple_violation_template_targeted_t2=\\\n",
    "Template(\"SELECT DISTINCT $t1_desc,$t2_desc FROM $table t1, $table t2 WHERE $dc_desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "601045b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_q = f\"select * from flights_new limit 1\"\n",
    "df_row = pd.read_sql(cols_q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e85a6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv('../../../../flights_dc_finder_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d1f0d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>ORIGIN_STATE_ABR</th>\n",
       "      <th>ORIGIN_STATE_NM</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEST_STATE_ABR</th>\n",
       "      <th>DEST_STATE_NM</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>MQ</td>\n",
       "      <td>3496</td>\n",
       "      <td>10728</td>\n",
       "      <td>BPT</td>\n",
       "      <td>Beaumont\"/\"Port Arthur TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas\"/\"Fort Worth TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1027</td>\n",
       "      <td>1019</td>\n",
       "      <td>1150</td>\n",
       "      <td>1138.\"0\"</td>\n",
       "      <td>79.\"0\"</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>25/01/2019</td>\n",
       "      <td>UA</td>\n",
       "      <td>592</td>\n",
       "      <td>13930</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>12892</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>1539</td>\n",
       "      <td>1555</td>\n",
       "      <td>1815</td>\n",
       "      <td>1806.\"0\"</td>\n",
       "      <td>251.\"0\"</td>\n",
       "      <td>1744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>08/01/2019</td>\n",
       "      <td>AA</td>\n",
       "      <td>2615</td>\n",
       "      <td>10849</td>\n",
       "      <td>BZN</td>\n",
       "      <td>Bozeman MT</td>\n",
       "      <td>MT</td>\n",
       "      <td>Montana</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas\"/\"Fort Worth TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1348</td>\n",
       "      <td>1347</td>\n",
       "      <td>1748</td>\n",
       "      <td>1733.\"0\"</td>\n",
       "      <td>166.\"0\"</td>\n",
       "      <td>1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17/01/2019</td>\n",
       "      <td>NK</td>\n",
       "      <td>711</td>\n",
       "      <td>11433</td>\n",
       "      <td>DTW</td>\n",
       "      <td>Detroit MI</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>12889</td>\n",
       "      <td>LAS</td>\n",
       "      <td>Las Vegas NV</td>\n",
       "      <td>NV</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>1923</td>\n",
       "      <td>1920</td>\n",
       "      <td>2102</td>\n",
       "      <td>2120.\"0\"</td>\n",
       "      <td>300.\"0\"</td>\n",
       "      <td>1749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>29/01/2019</td>\n",
       "      <td>OO</td>\n",
       "      <td>3092</td>\n",
       "      <td>12892</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>14869</td>\n",
       "      <td>SLC</td>\n",
       "      <td>Salt Lake City UT</td>\n",
       "      <td>UT</td>\n",
       "      <td>Utah</td>\n",
       "      <td>1552</td>\n",
       "      <td>1607</td>\n",
       "      <td>1843</td>\n",
       "      <td>1852.\"0\"</td>\n",
       "      <td>105.\"0\"</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>5</td>\n",
       "      <td>04/01/2019</td>\n",
       "      <td>WN</td>\n",
       "      <td>575</td>\n",
       "      <td>10693</td>\n",
       "      <td>BNA</td>\n",
       "      <td>Nashville TN</td>\n",
       "      <td>TN</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>14679</td>\n",
       "      <td>SAN</td>\n",
       "      <td>San Diego CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>1350</td>\n",
       "      <td>1417</td>\n",
       "      <td>1620</td>\n",
       "      <td>1620.\"0\"</td>\n",
       "      <td>243.\"0\"</td>\n",
       "      <td>1751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>EV</td>\n",
       "      <td>4299</td>\n",
       "      <td>11042</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Cleveland OH</td>\n",
       "      <td>OH</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>12264</td>\n",
       "      <td>IAD</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>VA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>600</td>\n",
       "      <td>558</td>\n",
       "      <td>724</td>\n",
       "      <td>703.\"0\"</td>\n",
       "      <td>65.\"0\"</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>28/01/2019</td>\n",
       "      <td>AA</td>\n",
       "      <td>1114</td>\n",
       "      <td>14100</td>\n",
       "      <td>PHL</td>\n",
       "      <td>Philadelphia PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>13303</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Miami FL</td>\n",
       "      <td>FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>1345</td>\n",
       "      <td>1338</td>\n",
       "      <td>1648</td>\n",
       "      <td>1635.\"0\"</td>\n",
       "      <td>177.\"0\"</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>6</td>\n",
       "      <td>12/01/2019</td>\n",
       "      <td>AA</td>\n",
       "      <td>301</td>\n",
       "      <td>12892</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>11503</td>\n",
       "      <td>EGE</td>\n",
       "      <td>Eagle CO</td>\n",
       "      <td>CO</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>840</td>\n",
       "      <td>836</td>\n",
       "      <td>1204</td>\n",
       "      <td>1155.\"0\"</td>\n",
       "      <td>139.\"0\"</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>5</td>\n",
       "      <td>04/01/2019</td>\n",
       "      <td>WN</td>\n",
       "      <td>1895</td>\n",
       "      <td>13204</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Orlando FL</td>\n",
       "      <td>FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>14730</td>\n",
       "      <td>SDF</td>\n",
       "      <td>Louisville KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>925</td>\n",
       "      <td>923</td>\n",
       "      <td>1135</td>\n",
       "      <td>1107.\"0\"</td>\n",
       "      <td>104.\"0\"</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DAY_OF_WEEK     FL_DATE OP_UNIQUE_CARRIER  OP_CARRIER_FL_NUM  \\\n",
       "0              4  10/01/2019                MQ               3496   \n",
       "1              5  25/01/2019                UA                592   \n",
       "2              2  08/01/2019                AA               2615   \n",
       "3              4  17/01/2019                NK                711   \n",
       "4              2  29/01/2019                OO               3092   \n",
       "..           ...         ...               ...                ...   \n",
       "494            5  04/01/2019                WN                575   \n",
       "495            2  01/01/2019                EV               4299   \n",
       "496            1  28/01/2019                AA               1114   \n",
       "497            6  12/01/2019                AA                301   \n",
       "498            5  04/01/2019                WN               1895   \n",
       "\n",
       "     ORIGIN_AIRPORT_ID ORIGIN           ORIGIN_CITY_NAME ORIGIN_STATE_ABR  \\\n",
       "0                10728    BPT  Beaumont\"/\"Port Arthur TX               TX   \n",
       "1                13930    ORD                 Chicago IL               IL   \n",
       "2                10849    BZN                 Bozeman MT               MT   \n",
       "3                11433    DTW                 Detroit MI               MI   \n",
       "4                12892    LAX             Los Angeles CA               CA   \n",
       "..                 ...    ...                        ...              ...   \n",
       "494              10693    BNA               Nashville TN               TN   \n",
       "495              11042    CLE               Cleveland OH               OH   \n",
       "496              14100    PHL            Philadelphia PA               PA   \n",
       "497              12892    LAX             Los Angeles CA               CA   \n",
       "498              13204    MCO                 Orlando FL               FL   \n",
       "\n",
       "    ORIGIN_STATE_NM  DEST_AIRPORT_ID DEST          DEST_CITY_NAME  \\\n",
       "0             Texas            11298  DFW  Dallas\"/\"Fort Worth TX   \n",
       "1          Illinois            12892  LAX          Los Angeles CA   \n",
       "2           Montana            11298  DFW  Dallas\"/\"Fort Worth TX   \n",
       "3          Michigan            12889  LAS            Las Vegas NV   \n",
       "4        California            14869  SLC       Salt Lake City UT   \n",
       "..              ...              ...  ...                     ...   \n",
       "494       Tennessee            14679  SAN            San Diego CA   \n",
       "495            Ohio            12264  IAD           Washington DC   \n",
       "496    Pennsylvania            13303  MIA                Miami FL   \n",
       "497      California            11503  EGE                Eagle CO   \n",
       "498         Florida            14730  SDF           Louisville KY   \n",
       "\n",
       "    DEST_STATE_ABR DEST_STATE_NM  CRS_DEP_TIME  DEP_TIME  CRS_ARR_TIME  \\\n",
       "0               TX         Texas          1027      1019          1150   \n",
       "1               CA    California          1539      1555          1815   \n",
       "2               TX         Texas          1348      1347          1748   \n",
       "3               NV        Nevada          1923      1920          2102   \n",
       "4               UT          Utah          1552      1607          1843   \n",
       "..             ...           ...           ...       ...           ...   \n",
       "494             CA    California          1350      1417          1620   \n",
       "495             VA      Virginia           600       558           724   \n",
       "496             FL       Florida          1345      1338          1648   \n",
       "497             CO      Colorado           840       836          1204   \n",
       "498             KY      Kentucky           925       923          1135   \n",
       "\n",
       "     ARR_TIME ACTUAL_ELAPSED_TIME  DISTANCE  \n",
       "0    1138.\"0\"              79.\"0\"       270  \n",
       "1    1806.\"0\"             251.\"0\"      1744  \n",
       "2    1733.\"0\"             166.\"0\"      1163  \n",
       "3    2120.\"0\"             300.\"0\"      1749  \n",
       "4    1852.\"0\"             105.\"0\"       590  \n",
       "..        ...                 ...       ...  \n",
       "494  1620.\"0\"             243.\"0\"      1751  \n",
       "495   703.\"0\"              65.\"0\"       288  \n",
       "496  1635.\"0\"             177.\"0\"      1013  \n",
       "497  1155.\"0\"             139.\"0\"       748  \n",
       "498  1107.\"0\"             104.\"0\"       719  \n",
       "\n",
       "[499 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df['_tid_']=range(len(csv_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea24e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=list(df_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73b2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_query_for_violation(role, dc_text, target_table, targeted, cols): \n",
    "    predicates = dc_text.split('&')\n",
    "#     clause = parse_rule_to_where_clause(dc_text)\n",
    "    constants=[]\n",
    "    # print(f\"t_interest:{t_interest}\")\n",
    "    need_tid=True \n",
    "    # if the constraint only has equals, we need to add an artificial\n",
    "    # key (_tid_) to differentiate tuples in violation with the tuple it\n",
    "    # self\n",
    "    for pred in predicates[2:]:\n",
    "        if(not eq_op.search(pred)):\n",
    "            need_tid=False\n",
    "        attr = re.search(r't[1|2]\\.([-\\w]+)', pred).group(1).lower()\n",
    "        # print(attr)\n",
    "#         constants.append(f'{role}.{attr}=\\'{t_interest[attr]}\\'')\n",
    "    constants_clause = ' AND '.join(constants)\n",
    "    # print(f\"dc_text:{dc_text}\")\n",
    "    t1_cols=', '.join([f't1.{x} as t1_{x}' for x in cols])\n",
    "    t2_cols=', '.join([f't2.{x} as t2_{x}' for x in cols])\n",
    "    \n",
    "    if(role=='t1'):\n",
    "        template=dc_tuple_violation_template_targeted_t1\n",
    "    else:\n",
    "        template=dc_tuple_violation_template_targeted_t2\n",
    "    if(targeted):\n",
    "        r_q  = template.substitute(t1_desc=t1_cols, t2_desc=t2_cols,\n",
    "                                   table=target_table, dc_desc=parse_rule_to_where_clause(dc_text),\n",
    "                                           tuple_desc=constants_clause)\n",
    "\n",
    "    else:\n",
    "        r_q  = template.substitute(t1_desc=t1_cols, t2_desc=t2_cols,\n",
    "                                   table=target_table, dc_desc=parse_rule_to_where_clause(dc_text))\n",
    "\n",
    "        r_q+=f\" AND t1._tid_!=t2._tid_\"\n",
    "#     print(r_q)\n",
    "\n",
    "    return r_q\n",
    "\n",
    "def find_tuples_in_violation(conn, dc_text, target_table, cols, targeted=False):\n",
    "    if(non_symetric_op.search(dc_text)):\n",
    "        q1= construct_query_for_violation('t1', dc_text, target_table, targeted)\n",
    "        q2 = construct_query_for_violation('t2', dc_text, target_table, targeted)\n",
    "        res = {'t1': pd.read_sql(q1, conn).to_dict('records'), \n",
    "        't2': pd.read_sql(q2, conn).to_dict('records')}\n",
    "    else:\n",
    "        q1= construct_query_for_violation('t1', dc_text, target_table, targeted, cols)\n",
    "        print(q1)\n",
    "        res = {'t1':pd.read_sql(q1, conn).to_dict('records')}\n",
    "        # print(res)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6090d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_file='/home/opc/author/RBBM/rbbm_src/muse/data/mas/flights_dcfinder_rules.txt'\n",
    "table_name='flights_dc_finder_input'\n",
    "res=[]\n",
    "rule_texts=[]\n",
    "try:\n",
    "    with open(dc_file, \"r\") as file:\n",
    "        for line in file:\n",
    "            rule_texts.append(line.strip())\n",
    "            # rules_from_line = [(table_name, x) for x in convert_dc_to_muse_rule(line, 'adult', 't1')]\n",
    "#             rules_from_line = [(table_name, x) for x in convert_dc_to_muse_rule(line, 'flights_new', 't1')]\n",
    "#             res.extend(rules_from_line)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "except IOError:\n",
    "    print(\"Error reading the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86477831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "print(len(rule_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb0f202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_tuples = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08190527",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_with_stats={r:{} for r in rule_texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a35d745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT t1.day_of_week as t1_day_of_week, t1.fl_date as t1_fl_date, t1.op_unique_carrier as t1_op_unique_carrier, t1.op_carrier_fl_num as t1_op_carrier_fl_num, t1.origin_airport_id as t1_origin_airport_id, t1.origin as t1_origin, t1.origin_city_name as t1_origin_city_name, t1.origin_state_abr as t1_origin_state_abr, t1.origin_state_nm as t1_origin_state_nm, t1.dest_airport_id as t1_dest_airport_id, t1.dest as t1_dest, t1.dest_city_name as t1_dest_city_name, t1.dest_state_abr as t1_dest_state_abr, t1.dest_state_nm as t1_dest_state_nm, t1.crs_dep_time as t1_crs_dep_time, t1.dep_time as t1_dep_time, t1.crs_arr_time as t1_crs_arr_time, t1.arr_time as t1_arr_time, t1.actual_elapsed_time as t1_actual_elapsed_time, t1.distance as t1_distance, t1._tid_ as t1__tid_, t1.is_dirty as t1_is_dirty,t2.day_of_week as t2_day_of_week, t2.fl_date as t2_fl_date, t2.op_unique_carrier as t2_op_unique_carrier, t2.op_carrier_fl_num as t2_op_carrier_fl_num, t2.origin_airport_id as t2_origin_airport_id, t2.origin as t2_origin, t2.origin_city_name as t2_origin_city_name, t2.origin_state_abr as t2_origin_state_abr, t2.origin_state_nm as t2_origin_state_nm, t2.dest_airport_id as t2_dest_airport_id, t2.dest as t2_dest, t2.dest_city_name as t2_dest_city_name, t2.dest_state_abr as t2_dest_state_abr, t2.dest_state_nm as t2_dest_state_nm, t2.crs_dep_time as t2_crs_dep_time, t2.dep_time as t2_dep_time, t2.crs_arr_time as t2_crs_arr_time, t2.arr_time as t2_arr_time, t2.actual_elapsed_time as t2_actual_elapsed_time, t2.distance as t2_distance, t2._tid_ as t2__tid_, t2.is_dirty as t2_is_dirty FROM flights_dc_finder_input t1, flights_dc_finder_input t2 WHERE t1.DEST_STATE_ABR=t2.DEST_STATE_ABR AND t1.ORIGIN_AIRPORT_ID=t2.ORIGIN_AIRPORT_ID AND t1._tid_!=t2._tid_\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT DISTINCT t1.day_of_week as t1_day_of_week, t1.fl_date as t1_fl_date, t1.op_unique_carrier as t1_op_unique_carrier, t1.op_carrier_fl_num as t1_op_carrier_fl_num, t1.origin_airport_id as t1_origin_airport_id, t1.origin as t1_origin, t1.origin_city_name as t1_origin_city_name, t1.origin_state_abr as t1_origin_state_abr, t1.origin_state_nm as t1_origin_state_nm, t1.dest_airport_id as t1_dest_airport_id, t1.dest as t1_dest, t1.dest_city_name as t1_dest_city_name, t1.dest_state_abr as t1_dest_state_abr, t1.dest_state_nm as t1_dest_state_nm, t1.crs_dep_time as t1_crs_dep_time, t1.dep_time as t1_dep_time, t1.crs_arr_time as t1_crs_arr_time, t1.arr_time as t1_arr_time, t1.actual_elapsed_time as t1_actual_elapsed_time, t1.distance as t1_distance, t1._tid_ as t1__tid_, t1.is_dirty as t1_is_dirty,t2.day_of_week as t2_day_of_week, t2.fl_date as t2_fl_date, t2.op_unique_carrier as t2_op_unique_carrier, t2.op_carrier_fl_num as t2_op_carrier_fl_num, t2.origin_airport_id as t2_origin_airport_id, t2.origin as t2_origin, t2.origin_city_name as t2_origin_city_name, t2.origin_state_abr as t2_origin_state_abr, t2.origin_state_nm as t2_origin_state_nm, t2.dest_airport_id as t2_dest_airport_id, t2.dest as t2_dest, t2.dest_city_name as t2_dest_city_name, t2.dest_state_abr as t2_dest_state_abr, t2.dest_state_nm as t2_dest_state_nm, t2.crs_dep_time as t2_crs_dep_time, t2.dep_time as t2_dep_time, t2.crs_arr_time as t2_crs_arr_time, t2.arr_time as t2_arr_time, t2.actual_elapsed_time as t2_actual_elapsed_time, t2.distance as t2_distance, t2._tid_ as t2__tid_, t2.is_dirty as t2_is_dirty FROM flights_dc_finder_input t1, flights_dc_finder_input t2 WHERE t1.DEST_STATE_ABR=t2.DEST_STATE_ABR AND t1.ORIGIN_AIRPORT_ID=t2.ORIGIN_AIRPORT_ID AND t1._tid_!=t2._tid_': column t1._tid_ does not exist\nLINE 1: ..._actual_elapsed_time, t1.distance as t1_distance, t1._tid_ a...\n                                                             ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedColumn\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/io/sql.py:2019\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2019\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mUndefinedColumn\u001b[0m: column t1._tid_ does not exist\nLINE 1: ..._actual_elapsed_time, t1.distance as t1_distance, t1._tid_ a...\n                                                             ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rule_texts:\n\u001b[0;32m----> 2\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfind_tuples_in_violation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrule: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m res:\n",
      "Cell \u001b[0;32mIn [5], line 48\u001b[0m, in \u001b[0;36mfind_tuples_in_violation\u001b[0;34m(conn, dc_text, target_table, cols, targeted)\u001b[0m\n\u001b[1;32m     46\u001b[0m     q1\u001b[38;5;241m=\u001b[39m construct_query_for_violation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt1\u001b[39m\u001b[38;5;124m'\u001b[39m, dc_text, target_table, targeted, cols)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(q1)\n\u001b[0;32m---> 48\u001b[0m     res \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt1\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)}\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# print(res)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/io/sql.py:565\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    562\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/io/sql.py:2079\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2068\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2069\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2075\u001b[0m     dtype: DtypeArg \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2076\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m   2078\u001b[0m     args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m-> 2079\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2080\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/io/sql.py:2031\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2028\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2030\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2031\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT DISTINCT t1.day_of_week as t1_day_of_week, t1.fl_date as t1_fl_date, t1.op_unique_carrier as t1_op_unique_carrier, t1.op_carrier_fl_num as t1_op_carrier_fl_num, t1.origin_airport_id as t1_origin_airport_id, t1.origin as t1_origin, t1.origin_city_name as t1_origin_city_name, t1.origin_state_abr as t1_origin_state_abr, t1.origin_state_nm as t1_origin_state_nm, t1.dest_airport_id as t1_dest_airport_id, t1.dest as t1_dest, t1.dest_city_name as t1_dest_city_name, t1.dest_state_abr as t1_dest_state_abr, t1.dest_state_nm as t1_dest_state_nm, t1.crs_dep_time as t1_crs_dep_time, t1.dep_time as t1_dep_time, t1.crs_arr_time as t1_crs_arr_time, t1.arr_time as t1_arr_time, t1.actual_elapsed_time as t1_actual_elapsed_time, t1.distance as t1_distance, t1._tid_ as t1__tid_, t1.is_dirty as t1_is_dirty,t2.day_of_week as t2_day_of_week, t2.fl_date as t2_fl_date, t2.op_unique_carrier as t2_op_unique_carrier, t2.op_carrier_fl_num as t2_op_carrier_fl_num, t2.origin_airport_id as t2_origin_airport_id, t2.origin as t2_origin, t2.origin_city_name as t2_origin_city_name, t2.origin_state_abr as t2_origin_state_abr, t2.origin_state_nm as t2_origin_state_nm, t2.dest_airport_id as t2_dest_airport_id, t2.dest as t2_dest, t2.dest_city_name as t2_dest_city_name, t2.dest_state_abr as t2_dest_state_abr, t2.dest_state_nm as t2_dest_state_nm, t2.crs_dep_time as t2_crs_dep_time, t2.dep_time as t2_dep_time, t2.crs_arr_time as t2_crs_arr_time, t2.arr_time as t2_arr_time, t2.actual_elapsed_time as t2_actual_elapsed_time, t2.distance as t2_distance, t2._tid_ as t2__tid_, t2.is_dirty as t2_is_dirty FROM flights_dc_finder_input t1, flights_dc_finder_input t2 WHERE t1.DEST_STATE_ABR=t2.DEST_STATE_ABR AND t1.ORIGIN_AIRPORT_ID=t2.ORIGIN_AIRPORT_ID AND t1._tid_!=t2._tid_': column t1._tid_ does not exist\nLINE 1: ..._actual_elapsed_time, t1.distance as t1_distance, t1._tid_ a...\n                                                             ^\n"
     ]
    }
   ],
   "source": [
    "for r in rule_texts:\n",
    "    res = find_tuples_in_violation(conn, r, table_name, cols)\n",
    "    print(f\"rule: {r}\")\n",
    "    for k in res:\n",
    "        for pair in res[k]:\n",
    "#             if(pair['t1_is_dirty']!=pair['t2_is_dirty']):\n",
    "            dirty_tuples.add(pair['t1__tid_'])\n",
    "            dirty_tuples.add(pair['t2__tid_'])\n",
    "        len_cc = len([x for x in res[k] if (x['t1_is_dirty']==False and x['t2_is_dirty']==False)])\n",
    "        len_non_cc = len([x for x in res[k] if not (x['t1_is_dirty']==False and x['t2_is_dirty']==False)])\n",
    "        len_dd = len([x for x in res[k] if (x['t1_is_dirty']==True and x['t2_is_dirty']==True)])\n",
    "        len_dc = len([x for x in res[k] if ((x['t1_is_dirty']==True and x['t2_is_dirty']==False) or \\\n",
    "                    (x['t1_is_dirty']==False and x['t2_is_dirty']==True))])\n",
    "        rules_with_stats[r]['len_cc']=len_cc\n",
    "        rules_with_stats[r]['len_dd']=len_dd\n",
    "        rules_with_stats[r]['len_dc']=len_dc\n",
    "        print(f\"number of ccs:{len_cc}, number of non ccs: {len_non_cc}, number of dds: {len_dd}, number of dcs:{len_dc}\")\n",
    "#     break\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54012aea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirty_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a534800",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dirty_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d54f45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rules_with_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749d503",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted(rules_with_stats, key=lambda k: rules_with_stats[k]['len_cc'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c51b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list({k:v for k,v in rules_with_stats.items() if v['len_cc']==0})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
