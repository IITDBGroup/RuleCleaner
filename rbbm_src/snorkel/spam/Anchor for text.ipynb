{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import sklearn.ensemble\n",
    "import spacy\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from anchor import anchor_text\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset from http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "# Link: http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\n",
    "def load_polarity(path='/home/zjmiao/Documents/labelling_explanation/rt-polaritydata'):\n",
    "    data = []\n",
    "    labels = []\n",
    "    f_names = ['rt-polarity.neg', 'rt-polarity.pos']\n",
    "    for (l, f) in enumerate(f_names):\n",
    "        for line in open(os.path.join(path, f), 'rb'):\n",
    "            try:\n",
    "                line.decode('utf8')\n",
    "            except:\n",
    "                continue\n",
    "            data.append(line.strip())\n",
    "            labels.append(l)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note: you must have spacy installed. Run:\n",
    "\n",
    "        pip install spacy && python -m spacy download en_core_web_lg\n",
    "\n",
    "If you want to run BERT, you can use the smaller spacy model, and you have to install transformers and torch or tf: \n",
    "\n",
    "        pip install torch transformers spacy && python -m spacy download en_core_web_sm\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "# Uncomment this if you're using BERT\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_polarity()\n",
    "train, test, train_labels, test_labels = sklearn.model_selection.train_test_split(data, labels, test_size=.2, random_state=42)\n",
    "train, val, train_labels, val_labels = sklearn.model_selection.train_test_split(train, train_labels, test_size=.1, random_state=42)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectorizer.fit(train)\n",
    "train_vectors = vectorizer.transform(train)\n",
    "test_vectors = vectorizer.transform(test)\n",
    "val_vectors = vectorizer.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy 0.7544910179640718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zjmiao/Documents/snorkel-tutorials/.envsnorkel/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "c = sklearn.linear_model.LogisticRegression()\n",
    "# c = sklearn.ensemble.RandomForestClassifier(n_estimators=500, n_jobs=10)\n",
    "c.fit(train_vectors, train_labels)\n",
    "preds = c.predict(val_vectors)\n",
    "print('Val accuracy', sklearn.metrics.accuracy_score(val_labels, preds))\n",
    "def predict_lr(texts):\n",
    "    res = c.predict(vectorizer.transform(texts))\n",
    "    print(texts, res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining a prediction\n",
    "use_unk_distribution=True means we will perturb examples by replacing words with UNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_text.AnchorText(nlp, [0, 1], use_unk_distribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a good book .'] [1]\n",
      "['This is a good book .'] [1]\n",
      "Prediction: 1\n",
      "['This is a good book .'] [1]\n",
      "['This is a UNK book UNK'] [0]\n",
      "['This UNK a good UNK .'] [1]\n",
      "['UNK is a UNK UNK .'] [0]\n",
      "['This is UNK good book UNK', 'This is a good book .', 'This UNK UNK good book UNK', 'This UNK a good UNK .', 'This is a good UNK .', 'This UNK a good UNK .', 'This is a UNK UNK UNK', 'This is UNK UNK book .', 'This is a UNK book UNK', 'This UNK a UNK book .'] [1 1 1 1 1 1 0 0 0 0]\n",
      "['UNK is UNK good UNK UNK', 'This is a good UNK .', 'This UNK a good UNK UNK', 'This is a good UNK UNK', 'This is a good book UNK', 'UNK is a good book UNK', 'UNK UNK a good UNK UNK', 'This is UNK good book .', 'UNK is a good book .', 'This UNK a good book .'] [1 1 1 1 1 1 1 1 1 1]\n",
      "['UNK is a good book UNK', 'UNK is a good UNK UNK', 'This is a good UNK UNK', 'UNK is UNK UNK UNK .', 'UNK is UNK UNK UNK .', 'UNK is a good book UNK', 'UNK is a good UNK UNK', 'UNK is UNK good book UNK', 'This is a UNK UNK UNK', 'This is a good book .'] [1 1 1 0 0 1 1 1 0 1]\n",
      "['UNK is a good UNK .', 'UNK is a good UNK .', 'UNK is UNK good book .', 'UNK UNK a good UNK .', 'This is UNK good book .', 'This is a good UNK UNK', 'UNK is UNK good UNK UNK', 'This UNK a good book UNK', 'This is UNK good UNK .', 'UNK UNK UNK good book UNK'] [1 1 1 1 1 1 1 1 1 1]\n",
      "['UNK is a good book .', 'UNK UNK a good book .', 'This UNK a good UNK UNK', 'This is a UNK book UNK', 'UNK is a good book UNK', 'This UNK a good UNK .', 'UNK is a UNK book .', 'This is a good UNK UNK', 'This UNK a UNK book .', 'This is a good book .'] [1 1 1 0 1 1 1 1 0 1]\n",
      "['This is UNK good UNK .', 'This UNK a good UNK .', 'UNK UNK a good book .', 'This is UNK good book .', 'UNK is a good book UNK', 'UNK is a good UNK .', 'This is UNK good book .', 'This is a good UNK .', 'This UNK UNK good book .', 'This is UNK good UNK UNK'] [1 1 1 1 1 1 1 1 1 1]\n",
      "['This UNK UNK UNK book .', 'This UNK UNK UNK book .', 'This is UNK UNK book .', 'UNK is UNK UNK book .', 'UNK is a good book .', 'This UNK UNK good book UNK', 'This UNK UNK good book .', 'This UNK a good book .', 'This UNK UNK good book .', 'UNK UNK UNK good book UNK'] [0 0 0 1 1 1 1 1 1 1]\n",
      "['UNK is a good book .', 'UNK is UNK good book UNK', 'This is a good book UNK', 'UNK UNK a good book .', 'This is a good UNK .', 'This UNK a good book UNK', 'UNK UNK UNK good UNK .', 'UNK UNK a good UNK .', 'This is UNK good book .', 'UNK is UNK good book UNK'] [1 1 1 1 1 1 1 1 1 1]\n",
      "['UNK is a UNK book .', 'This UNK UNK good book .', 'UNK is a UNK book .', 'UNK UNK a UNK UNK .', 'UNK UNK a UNK UNK .', 'UNK is UNK good book .', 'This is a UNK UNK .', 'UNK UNK a good book .', 'UNK UNK a good book .', 'This is a good UNK .'] [1 1 1 0 0 1 0 1 1 1]\n",
      "['UNK is a good UNK UNK', 'UNK UNK UNK good book UNK', 'UNK is UNK good UNK .', 'This UNK a good book UNK', 'This is a good book UNK', 'UNK is a good book UNK', 'This UNK a good UNK .', 'UNK UNK a good UNK UNK', 'This UNK UNK good UNK .', 'UNK is a good book .'] [1 1 1 1 1 1 1 1 1 1]\n",
      "['This UNK a UNK book UNK', 'UNK UNK a UNK UNK UNK', 'UNK UNK a good book UNK', 'UNK is a UNK UNK .', 'UNK UNK a good book .', 'This UNK a UNK book UNK', 'UNK UNK a good UNK UNK', 'UNK is a good UNK .', 'This is a good book UNK', 'This is a UNK book .'] [0 0 1 0 1 0 1 1 1 0]\n",
      "['This UNK a good UNK .', 'This is UNK good book UNK', 'UNK is UNK good book .', 'This UNK a good book UNK', 'This is a good book .', 'This UNK UNK good book UNK', 'This UNK a good book UNK', 'UNK UNK a good UNK UNK', 'UNK UNK UNK good UNK .', 'UNK is UNK good book UNK'] [1 1 1 1 1 1 1 1 1 1]\n",
      "['UNK is UNK UNK UNK UNK', 'UNK is UNK UNK book .', 'This is a UNK book .', 'UNK is UNK UNK UNK UNK', 'This is a good UNK .', 'UNK is a good UNK .', 'UNK is a UNK UNK .', 'This is UNK good book .', 'This is UNK good UNK UNK', 'UNK is a good UNK UNK'] [0 1 0 0 1 1 0 1 1 1]\n",
      "['UNK is a good book .', 'This UNK UNK good book .', 'UNK is UNK good UNK UNK', 'UNK is UNK good book UNK', 'This UNK UNK good book UNK', 'This UNK a good book UNK', 'This UNK UNK good book UNK', 'This is UNK good UNK UNK', 'UNK is a good UNK .', 'UNK is a good UNK .'] [1 1 1 1 1 1 1 1 1 1]\n",
      "['This is a UNK book .', 'UNK is a UNK book UNK', 'This UNK a UNK book .', 'This is UNK UNK book UNK', 'UNK is a UNK book .', 'UNK is UNK UNK book .', 'This UNK a good book .', 'UNK UNK a good book .', 'UNK UNK a UNK book .', 'This is UNK UNK book UNK'] [0 1 0 0 1 1 1 1 0 0]\n",
      "['UNK is UNK good UNK .', 'UNK UNK UNK good book .', 'UNK UNK a good UNK .', 'This UNK a good book UNK', 'UNK is UNK good book .', 'UNK UNK a good book .', 'UNK UNK a good UNK UNK', 'UNK is a good UNK UNK', 'UNK UNK a good book .', 'UNK UNK a good UNK UNK'] [1 1 1 1 1 1 1 1 1 1]\n",
      "['This is a good UNK .', 'This UNK UNK UNK book .', 'This is a good book .', 'This UNK UNK UNK UNK .', 'This UNK a UNK UNK .', 'UNK is UNK UNK UNK .', 'This UNK a UNK UNK .', 'UNK UNK UNK UNK UNK .', 'UNK UNK UNK good book .', 'This UNK UNK good UNK .'] [1 0 1 0 0 0 0 0 1 1]\n",
      "['This UNK UNK good UNK UNK', 'This is a good book .', 'This is a good book UNK', 'This is UNK good book UNK', 'UNK is UNK good UNK UNK', 'This UNK a good book UNK', 'This is UNK good UNK .', 'This UNK UNK good UNK UNK', 'This is a good UNK UNK', 'UNK UNK UNK good book UNK'] [1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "text = 'This is a good book .'\n",
    "pred = explainer.class_names[predict_lr([text])[0]]\n",
    "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
    "print('Prediction: %s' % pred)\n",
    "exp = explainer.explain_instance(text, predict_lr, threshold=0.95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the anchor. Note that using this perturbation distribution, having the word 'good' in the text virtually guarantees a positive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: good\n",
      "Precision: 1.00\n",
      "\n",
      "Examples where anchor applies and model predicts 1:\n",
      "\n",
      "This UNK UNK good UNK .\n",
      "UNK is a good UNK .\n",
      "This UNK UNK good book .\n",
      "UNK UNK a good book .\n",
      "UNK UNK UNK good book .\n",
      "This is UNK good book .\n",
      "UNK is UNK good book UNK\n",
      "UNK is UNK good UNK UNK\n",
      "UNK is a good book .\n",
      "UNK UNK a good UNK UNK\n",
      "\n",
      "Examples where anchor applies and model predicts 0:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % pred)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_different_prediction=True)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the distribution\n",
    "Let's try this with another perturbation distribution, namely one that replaces words by similar words instead of UNKS, using word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=False, use_bert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "text = 'This is a good book .'\n",
    "pred = explainer.class_names[predict_lr([text])[0]]\n",
    "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
    "print('Prediction: %s' % pred)\n",
    "exp = explainer.explain_instance(text, predict_lr, threshold=0.95, verbose=False, use_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the anchor now. Note that with this distribution, we need more to guarantee a prediction of positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: good AND book AND is\n",
      "Precision: 1.00\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "\n",
      "THIS is the good book .\n",
      "THis is each good book .\n",
      "Another is an good book .\n",
      "Both is both good book .\n",
      "Every is the good book .\n",
      "A is an good book .\n",
      "THESE is an good book .\n",
      "THIS is a good book .\n",
      "THis is a good book .\n",
      "ANOTHER is some good book .\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % pred)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(only_different_prediction=True)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the partial anchor 'good' to see why it's not sufficient in this case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial anchor: good\n",
      "Precision: 0.85\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "\n",
      "This refers any good book .\n",
      "SOME sits a good lesson .\n",
      "A believes a good synopsis .\n",
      "The brings a good preface .\n",
      "Any suggests an good cookbook .\n",
      "THe is the good poetry .\n",
      "Every appears a good synopsis .\n",
      "Both makes this good publication .\n",
      "THis looks this good hardcover .\n",
      "Those becomes an good autobiography .\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "\n",
      "A falls another good story .\n",
      "This falls any good paperback .\n",
      "Another contains some good publisher .\n",
      "This reminds a good issue .\n",
      "THIS wants another good fantasy .\n",
      "Some creates the good everything .\n",
      "The goes a good textbook .\n",
      "Some remains every good lecture .\n",
      "SOME occurs any good biography .\n",
      "SOME has every good textbook .\n"
     ]
    }
   ],
   "source": [
    "print('Partial anchor: %s' % (' AND '.join(exp.names(0))))\n",
    "print('Precision: %.2f' % exp.precision(0))\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % pred)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_same_prediction=True)]))\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_different_prediction=True)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution above is a bit naive, and you get a lot of sentences that don't look realistic.  \n",
    "Let's use BERT to perturb the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zjmiao/Documents/snorkel-tutorials/.envsnorkel/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "explainer = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=False, use_bert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n",
      "Time: 41.04053235054016\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "text = 'This is a good book .'\n",
    "pred = explainer.class_names[predict_lr([text])[0]]\n",
    "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
    "print('Prediction: %s' % pred)\n",
    "b = time.time()\n",
    "exp = explainer.explain_instance(text, predict_lr, threshold=0.95, verbose=False)\n",
    "print('Time: %s' % (time.time() - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: good AND book AND is\n",
      "Precision: 0.99\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "\n",
      "This is a good book .\n",
      "What is a good book .\n",
      "this is a good book award\n",
      "it is another good book .\n",
      "this is a good book ?\n",
      "Your is damn good book .\n",
      "Allah is your good book .\n",
      "here is always good book editor\n",
      "This is a good book .\n",
      "Help is a good book review\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "\n",
      "everything is a good book !\n"
     ]
    }
   ],
   "source": [
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % pred)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(only_different_prediction=True)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the partial anchor 'good' to see why it's not sufficient in this case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial anchor: good\n",
      "Precision: 0.88\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "\n",
      "hers is a good fare .\n",
      "• are a good at !\n",
      "Where ##s a good photo student\n",
      "here is said good word ;\n",
      "it is a good growth .\n",
      "music is a good job .\n",
      "\" = become good rid •\n",
      "they ##um your good luck .\n",
      "for do · good di :\n",
      "it is a good luck movie\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "\n",
      "weather is not good behavior .\n",
      "we needs a good bath ;\n",
      "there is a good neighbourhood affair\n",
      "Neither indicates despite good news .\n",
      "thirst is a good idea !\n",
      "this is a good animal .\n",
      "\" is very good horse !\n",
      "God is also good weather .\n",
      ") , a good strategy edition\n",
      "only . ‘ good ##will >\n"
     ]
    }
   ],
   "source": [
    "print('Partial anchor: %s' % (' AND '.join(exp.names(0))))\n",
    "print('Precision: %.2f' % exp.precision(0))\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % pred)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_same_prediction=True)]))\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_different_prediction=True)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the examples are much more varied than just using word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are sampling from BERT sequentially above (one mask at a time), to get sentences that are more coherent.  \n",
    "If you want to do a single BERT pass per sample, you can set `onepass=True`. You may lose some coherence, but it will be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n",
      "Time: 1.6398329734802246\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "text = 'This is a good book .'\n",
    "pred = explainer.class_names[predict_lr([text])[0]]\n",
    "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
    "print('Prediction: %s' % pred)\n",
    "b = time.time()\n",
    "exp = explainer.explain_instance(text, predict_lr, threshold=0.95, verbose=False, onepass=True)\n",
    "print('Time: %s' % (time.time() - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: good AND book AND is\n",
      "Precision: 0.99\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "\n",
      "This is a good book .\n",
      "What is a good book .\n",
      "this is a good book award\n",
      "it is another good book .\n",
      "this is a good book ?\n",
      "Your is damn good book .\n",
      "Allah is your good book .\n",
      "here is always good book editor\n",
      "This is a good book .\n",
      "Help is a good book review\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "\n",
      "everything is a good book !\n"
     ]
    }
   ],
   "source": [
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % pred)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(only_different_prediction=True)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the partial anchor 'good' to see why it's not sufficient in this case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial anchor: good\n",
      "Precision: 0.88\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "\n",
      "This is a good book .\n",
      "What is a good book .\n",
      "this is a good book award\n",
      "it is another good book .\n",
      "this is a good book ?\n",
      "Your is damn good book .\n",
      "Allah is your good book .\n",
      "here is always good book editor\n",
      "This is a good book .\n",
      "Help is a good book review\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "\n",
      "everything is a good book !\n"
     ]
    }
   ],
   "source": [
    "print('Partial anchor: %s' % (' AND '.join(exp.names(0))))\n",
    "print('Precision: %.2f' % exp.precision(0))\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % pred)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(partial_index=2, only_same_prediction=True)]))\n",
    "print()\n",
    "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
    "print()\n",
    "print('\\n'.join([x[0] for x in exp.examples(partial_index=2, only_different_prediction=True)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See a visualization of the anchor with examples and etc (won't work if you're seeing this on github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
